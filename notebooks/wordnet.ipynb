{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Finding Images and using WordNet\n",
    "\n",
    "This notebook will demonstrate loading images from google image search and using WordNet to find similar words.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The ```compsyn.helperfunctions``` file contains helper functions to download files and to use NLTKs wordnet to find extra search terms."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from compsyn.helperfunctions import (\n",
    "    search_and_download, \n",
    "    run_google_vision, \n",
    "    write_img_classifications_to_file\n",
    ")\n",
    "from compsyn.wordnet_functions import get_wordnet_tree_data\n",
    "from compsyn.vectors import WordToColorVector\n",
    "from compsyn.trial import get_trial"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1616459788] (compsyn.Trial)  INFO: work_dir: /Volumes/LACIE/compsyn/notebook_work_dir\n",
      "[1616459788] (compsyn.Trial)  INFO: experiment: wordnet-example-0\n",
      "[1616459788] (compsyn.Trial)  INFO: trial_id: notebook\n",
      "[1616459788] (compsyn.Trial)  INFO: hostname: topside\n",
      "\n",
      " CompsynConfig\n",
      "\texperiment_name                          = wordnet-example-0\n",
      "\ttrial_id                                 = notebook\n",
      "\thostname                                 = topside\n",
      "\ttrial_timestamp                          = 2021-03-23\n",
      "\twork_dir                                 = /Volumes/LACIE/compsyn/notebook_work_dir\n",
      "\tjzazbz_array                             = /Volumes/LACIE/compsyn/jzazbz_array.npy\n",
      "\tgoogle_application_credentials           = /Volumes/LACIE/compsyn/compsyn3-8cf6580619a9.json\n",
      "\tdriver_browser                           = Firefox\n",
      "\tdriver_path                              = /usr/local/bin/geckodriver\n",
      "\ts3_bucket                                = None\n",
      "\ts3_region_name                           = None\n",
      "\ts3_endpoint_url                          = None\n",
      "\ts3_access_key_id                         = None\n",
      "\ts3_secret_access_key                     = None\n",
      "\tlog_level                                = 20\n",
      "\tlog_file                                 = None\n",
      "\n",
      " Trial\n",
      "\texperiment_name = wordnet-example-0\n",
      "\ttrial_id        = notebook\n",
      "\thostname        = topside\n"
     ]
    }
   ],
   "source": [
    "from compsyn.config import CompsynConfig\n",
    "COMPSYN_ROOT_DIR=\"/Volumes/LACIE/compsyn\" # change to a path on your local system where you store compsyn files\n",
    "config = CompsynConfig(\n",
    "    experiment_name=\"wordnet-example-0\",\n",
    "    trial_id=\"notebook\",\n",
    "    hostname=\"topside\",\n",
    "    work_dir=f\"{COMPSYN_ROOT_DIR}/notebook_work_dir\",\n",
    "    jzazbz_array=f\"{COMPSYN_ROOT_DIR}/jzazbz_array.npy\",\n",
    "    google_application_credentials=f\"{COMPSYN_ROOT_DIR}/compsyn3-8cf6580619a9.json\",\n",
    "    driver_path=\"/usr/local/bin/geckodriver\",\n",
    "    driver_browser=\"Firefox\",\n",
    ")\n",
    "trial = get_trial()\n",
    "print(\"\\n\", config)\n",
    "print(\"\\n\", trial)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "number_images = 100 \n",
    "search_terms = ['emotion']\n",
    "filter_data = True\n",
    "get_tree_data = True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get WordNet data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_categories = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adding Search Terms from Tree\n",
      "  ref_term                        new_term     role  \\\n",
      "0  emotion                           anger  hyponym   \n",
      "1  emotion                         anxiety  hyponym   \n",
      "2  emotion  conditioned_emotional_response  hyponym   \n",
      "3  emotion                 emotional_state  hyponym   \n",
      "4  emotion                            fear  hyponym   \n",
      "\n",
      "                                          synset Branch_fact Num_senses  \n",
      "0                           Synset('anger.n.01')          19          5  \n",
      "1                         Synset('anxiety.n.02')           6          2  \n",
      "2  Synset('conditioned_emotional_response.n.01')           1          1  \n",
      "3                 Synset('emotional_state.n.01')          16          1  \n",
      "4                            Synset('fear.n.01')          25          8  \n"
     ]
    }
   ],
   "source": [
    "if get_tree_data: \n",
    "    print(\"Adding Search Terms from Tree\")\n",
    "    tree_search_terms, raw_tree, all_tree_data = get_wordnet_tree_data(\n",
    "        search_terms=search_terms, \n",
    "        home=CompsynConfig().config[\"work_dir\"]\n",
    "    )\n",
    "    search_terms = tree_search_terms[:n_categories]\n",
    "    print(all_tree_data.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['emotion',\n",
       " 'emotional state',\n",
       " 'conditioned emotional response',\n",
       " 'anxiety',\n",
       " 'anger',\n",
       " 'joy',\n",
       " 'fear',\n",
       " 'love',\n",
       " 'hate',\n",
       " 'feeling']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tree_search_terms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['emotion',\n",
       " 'emotional state',\n",
       " 'conditioned emotional response',\n",
       " 'anxiety',\n",
       " 'anger',\n",
       " 'joy',\n",
       " 'fear',\n",
       " 'love',\n",
       " 'hate',\n",
       " 'feeling']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "search_terms"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We might want to remove the elements from the list which won't have clear images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "drop 'emotional state'\n",
      "drop 'conditioned emotional response'\n"
     ]
    }
   ],
   "source": [
    "print(\"drop\", f\"'{search_terms.pop(1)}'\")\n",
    "print(\"drop\", f\"'{search_terms.pop(1)}'\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Download Images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1616459837] (compsyn.fetch_image_urls)  INFO: 'emotion': 100 search results. Extracting links from 0:100\n",
      "[1616459919] (compsyn.search_and_download)  INFO: 94/100 images successfully downloaded for 'emotion'\n",
      "[1616459919] (compsyn.WordToColorVector.emotion)  INFO: saved 10.6KiB pickle to /Volumes/LACIE/compsyn/notebook_work_dir/wordnet-example-0/vectors/unnamed/emotion/w2cv.pickle\n",
      "[1616459925] (compsyn.fetch_image_urls)  INFO: 'anxiety': 100 search results. Extracting links from 0:100\n",
      "[1616460009] (compsyn.search_and_download)  INFO: 94/100 images successfully downloaded for 'anxiety'\n",
      "[1616460009] (compsyn.WordToColorVector.anxiety)  INFO: saved 11.3KiB pickle to /Volumes/LACIE/compsyn/notebook_work_dir/wordnet-example-0/vectors/unnamed/anxiety/w2cv.pickle\n",
      "[1616460015] (compsyn.fetch_image_urls)  INFO: 'anger': 100 search results. Extracting links from 0:100\n",
      "[1616460099] (compsyn.search_and_download)  INFO: 96/100 images successfully downloaded for 'anger'\n",
      "[1616460099] (compsyn.WordToColorVector.anger)  INFO: saved 10.5KiB pickle to /Volumes/LACIE/compsyn/notebook_work_dir/wordnet-example-0/vectors/unnamed/anger/w2cv.pickle\n",
      "[1616460104] (compsyn.fetch_image_urls)  INFO: 'joy': 100 search results. Extracting links from 0:100\n",
      "[1616460191] (compsyn.search_and_download)  INFO: 98/100 images successfully downloaded for 'joy'\n",
      "[1616460191] (compsyn.WordToColorVector.joy)  INFO: saved 10.8KiB pickle to /Volumes/LACIE/compsyn/notebook_work_dir/wordnet-example-0/vectors/unnamed/joy/w2cv.pickle\n",
      "[1616460197] (compsyn.fetch_image_urls)  INFO: 'fear': 100 search results. Extracting links from 0:100\n",
      "[1616460296] (compsyn.search_and_download)  INFO: 99/100 images successfully downloaded for 'fear'\n",
      "[1616460296] (compsyn.WordToColorVector.fear)  INFO: saved 10.8KiB pickle to /Volumes/LACIE/compsyn/notebook_work_dir/wordnet-example-0/vectors/unnamed/fear/w2cv.pickle\n",
      "[1616460301] (compsyn.fetch_image_urls)  INFO: 'love': 100 search results. Extracting links from 0:100\n",
      "[1616460382] (compsyn.search_and_download)  INFO: 97/100 images successfully downloaded for 'love'\n",
      "[1616460382] (compsyn.WordToColorVector.love)  INFO: saved 11.3KiB pickle to /Volumes/LACIE/compsyn/notebook_work_dir/wordnet-example-0/vectors/unnamed/love/w2cv.pickle\n",
      "[1616460387] (compsyn.fetch_image_urls)  INFO: 'hate': 100 search results. Extracting links from 0:100\n"
     ]
    }
   ],
   "source": [
    "img_urls_dict = {}\n",
    "\n",
    "# takes about 12 minutes\n",
    "for search_term in search_terms:\n",
    "    w2cv = WordToColorVector(label=search_term, trial=trial)\n",
    "    w2cv.run_image_capture()\n",
    "    # This logic makes this image capture resumable\n",
    "    if w2cv.raw_image_urls is None:\n",
    "        w2cv.load()\n",
    "    else:\n",
    "        w2cv.save()\n",
    "    img_urls_dict[search_term] = w2cv.raw_image_urls"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run Google Vision Filter "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['emotion', 'anger', 'love', 'feeling', 'joy', 'anxiety', 'hate', 'fear'])\n",
      "emotion\n",
      "anger\n",
      "love\n",
      "feeling\n",
      "joy\n",
      "hate\n",
      "fear\n",
      "[1616458327] (compsyn.run_google_vision)  INFO: Classifying Imgs. w. Google Vision API...\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "'NoneType' object is not iterable",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-14-a2605bf6599f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      5\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mimg_urls\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m             \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msearch_term\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m     \u001b[0mimg_classified_dict\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrun_google_vision\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg_urls_dict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m     \u001b[0mwrite_img_classifications_to_file\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhome\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msearch_terms\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimg_classified_dict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/checkout/comp-syn/compsyn/helperfunctions.py\u001b[0m in \u001b[0;36mrun_google_vision\u001b[0;34m(img_urls_dict)\u001b[0m\n\u001b[1;32m    355\u001b[0m         \u001b[0mimg_classified_dict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0msearch_term\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    356\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 357\u001b[0;31m         \u001b[0;32mfor\u001b[0m \u001b[0mimage_uri\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mimg_urls\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    358\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    359\u001b[0m                 \u001b[0mimage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msource\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimage_uri\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mimage_uri\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: 'NoneType' object is not iterable"
     ]
    }
   ],
   "source": [
    "print(img_urls_dict.keys())\n",
    "if filter_data: \n",
    "    for search_term in img_urls_dict.keys():\n",
    "        img_urls = img_urls_dict[search_term]\n",
    "        if img_urls is None:\n",
    "            print(search_term)\n",
    "    img_classified_dict = run_google_vision(img_urls_dict)\n",
    "    write_img_classifications_to_file(home, search_terms, img_classified_dict)\n",
    "    \n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You should now have the top 100 images of each of the elements of 'search_term' saved on your machine: you can now run the analysis presented in the ```compsyn_package_pipeline```."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
