from __future__ import annotations

import argparse
import os
from pathlib import Path

import boto3

from .logger import get_logger


class S3Error(Exception):
    pass


def get_s3_args(
    parser: Optional[argparse.ArgumentParser] = None,
) -> argparse.ArgumentParser:

    if parser is None:
        parser = argparse.ArgumentParser()

    s3_parser = parser.add_argument_group("s3")

    s3_parser.add_argument(
        "--s3-bucket",
        type=str,
        default=os.getenv("COMPSYN_S3_BUCKET", None),
        help="bucket where img data is stored in S3",
    )
    s3_parser.add_argument(
        "--s3-region-name",
        type=str,
        default=os.getenv("COMPSYN_S3_REGION_NAME", None),
        help="S3 region",
    )
    s3_parser.add_argument(
        "--s3-endpoint-url",
        default=os.getenv("COMPSYN_S3_ENDPOINT", None),
        help="S3 endpoint URL (only required for non-AWS S3)",
    )
    s3_parser.add_argument(
        "--s3-access-key-id",
        type=str,
        default=os.getenv("COMPSYN_S3_ACCESS_KEY_ID", None),
        required=True,
    )
    s3_parser.add_argument(
        "--s3-secret-access-key",
        type=str,
        default=os.getenv("COMPSYN_S3_SECRET_ACCESS_KEY", None),
        required=True,
    )

    return parser



def get_s3_client(args: argparse.Namespace) -> botocore.clients.s3:

    assert args.s3_region_name is not None, "set COMPSYN_S3_REGION_NAME"
    assert args.s3_access_key_id is not None, "set COMPSYN_S3_ACCESS_KEY_ID"
    assert args.s3_secret_access_key is not None, "set COMPSYN_S3_SECRET_ACCESS_KEY"
    assert args.s3_bucket is not None, "set COMPSYN_S3_BUCKET"

    return boto3.session.Session().client(
        "s3",
        region_name=args.s3_region_name,
        endpoint_url=args.s3_endpoint_url,
        aws_access_key_id=args.s3_access_key_id,
        aws_secret_access_key=args.s3_secret_access_key,
    )


def s3_object_exists(s3_path: Path) -> bool:

    s3_args, unknown = get_s3_args().parse_known_args()
    s3_client = get_s3_client(s3_args)
    log = get_logger("s3_object_exists")

    try:
        s3_client.get_object(Bucket=s3_args.s3_bucket, Key=str(s3_path))
        if not overwrite:
            return True
    except s3_client.exceptions.NoSuchKey:
        return False


def upload_file_to_s3(local_path: Path, s3_path: Path, overwrite: bool = False) -> None:

    s3_args, unknown = get_s3_args().parse_known_args()
    s3_client = get_s3_client(s3_args)
    log = get_logger("upload_file_to_s3")

    try:
        # only write files to s3 that don't already exist unless overwrite is passed
        if s3_object_exists(s3_path) and not overwrite:
            log.debug(
                f"s3://{s3_bucket}/{object_path} already exists in s3, not overwriting"
            )
            return

        s3_client.put_object(
            Body=local_path.read_bytes(), Bucket=s3_args.s3_bucket, Key=str(s3_path)
        )
        log.info(f"uploaded s3://{s3_args.s3_bucket}/{s3_path}")

    except s3_client.exceptions.ClientError:
        # catch and raise any errors generated by attempting to communicate with s3
        s3_client_attributes = {
            attr: getattr(s3_client, attr) for attr in s3_client.__dict__.keys()
        }
        s3_client_attributes.update(
            {"bucket": bucket, "object_path": object_path,}
        )
        raise S3Error(f"{s3_client_attributes} S3 ClientError")


def download_file_from_s3(
    local_path: Path, s3_path: Path, overwrite: bool = False
) -> None:

    s3_args, unknown = get_s3_args().parse_known_args()
    s3_client = get_s3_client(s3_args)
    log = get_logger("download_file_from_s3")

    try:
        # only download files from s3 that don't already exist locally unless overwrite is passed
        if local_path.is_file():
            if not overwrite:
                log.debug(f"{local_path} already exists locally, not overwriting")
                return

        s3_obj = s3_client.get_object(Bucket=s3_args.s3_bucket, Key=str(s3_path))
        local_path.write_bytes(s3_obj["Body"].read())
        log.info(f"downloaded {local_path} from s3")

    except s3_client.exceptions.ClientError:
        # catch and raise any errors generated by attempting to communicate with s3
        s3_client_attributes = {
            attr: getattr(s3_client, attr) for attr in s3_client.__dict__.keys()
        }
        s3_client_attributes.update(
            {"bucket": bucket, "object_path": object_path,}
        )
        raise S3Error(f"{s3_client_attributes} S3 ClientError")
